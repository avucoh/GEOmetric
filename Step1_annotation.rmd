---
title: "Step1"
author: "ANV"
date: "May 31, 2018"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

library(data.table)
library(GEOquery)
source("Code/misc.R")

# Specify a directory where GSE downloaded files are stored
GEOtemp <- "GEOtemp"

```

## Download GSEs
Feed in the ids of GSEs that passed Filter #1 (based on description). The following steps pull the metadata create a standardized annotation table for the samples.
```{r}
gses <- readLines("test.txt")

# Download the GSE
getSamples <- function(gse) {
  eset <- getGEO(GEO = gse, destdir = GEOtemp)[[1]]
  pData(eset)
}

results <- lapply(gses, function(x) try(getSamples(x)))
names(results) <- gses

```

Sometimes downloading a GEO will fail (maybe 1-5% of GSEs?) because there was a parsing error or some other problem, so check list:
```{r}

ok <- allOK(results)
table(ok)
results <- results[ok] # Check any failures later, proceed with OK

```

## Create and populate annotation table
Infer some annotation information for each GSE using some simple rules. 
This is only the starting point as data is imperfectly extracted; manual annotation follows for the exported table. 
```{r}

# Experiment Type (1-Channel or 2-Channel; more specific assignments, i.e. whether there was dye swap, happens in human review)
inferXPType <- function(DT) {
  default <- "1C"
  ch2 <- grep("source_name_ch2", names(DT))
  if(length(ch2)) return("2C")
  return(default)
}

ixpType <- sapply(results, inferXPType)

# BSM -- Molecule -- note: perhaps have a list of all known tlr ligands to match against
inferBSM <- function(DT) {
  x1 <- rep("", nrow(DT))
  bsmcol <- grep("agent|stimulation", names(DT)) # This won't work if columns weren't parsed
  if(sum(bsmcol)) {
    info <- do.call(paste, DT[, bsmcol])
    return(info)
  } 
  return(x1)
}

iBSM <- sapply(results, inferBSM)

# BSMDCD -- Time
inferDCD <- function(DT) {
  x1 <- rep("", nrow(DT))
  # First find a column that specifically contains treatment info
  tcol <- grep("^treatment|time", names(DT))
  if(sum(tcol)) {
    info <- do.call(paste, DT[, tcol])
  } else { # Use information in sample title
    info <- DT$title
  }
  m <- regexpr("[0-9]+ ?(d|h|D|H)|(D|d)(ay) ?[0-9]+", info)
  x1[m != -1] <- regmatches(info, m)
   # Sometimes time is stated as "overnight", which usually means "12 h"
  x1[grepl("overnight", info)] <- "12h"
  x1 <- tolower(gsub(" ", "", x1))
  return(x1)
}

iDCD <- sapply(results, inferDCD) 

# BSMDCD2 -- Dose/concentration
inferDCD2 <- function(DT) {
  x1 <- rep("", nrow(DT))
  dosecol <- grep("dose|concentration|amount|treatment", names(DT))
  if(sum(dosecol)) {
    info <- do.call(paste, DT[, dosecol])
    m <- regexpr("[0-9.]+ ?(u|n|m)(g|M)?\\/?([A-Za-z]{2})", info)
    x1[m != -1] <- regmatches(info, m)
  }
  return(x1)
}

iDCD2 <- sapply(results, inferDCD2) 

# BiosampName -- to do: a more sophisticated implementation could also match to biosample ID
biosamps <- readLines("biosamps.txt") ## This is a list derived from "allbiosamples"

inferBiosamp <- function(DT) {
  # First find the obvious columns, looking for one containing cell line/type first
  cellcol <- grep("^cell.*ch1", colnames(DT))
  if(sum(cellcol)) {
    cell <- do.call(paste, DT[, cellcol])
    return(cell)
  } else {
    tissuecol <- grep("^tissue.*ch1", colnames(DT))
    if(sum(tissuecol)) {
      tissue <- do.call(paste, DT[, tissuecol])
      return(tissue)
    } else { # Use the source_name_ch1 column
      biosample <- sapply(DT$source_name_ch1, function(x) biosamps[amatch(x, biosamps)])
      biosample[is.na(biosample)] <- "?"
      return(biosample)
    }
  }
}

iBiosamp <- sapply(results, inferBiosamp)

# Control?
inferCTRL <- function(DT) {
  s <- DT$title
  ctrl <- as.numeric(grepl("wt|wildtype|control|ctrl|healthy|media|medium|veh|unstim|untreated|mock", s, ignore.case = T))
}

iCTRL <- sapply(results, inferCTRL)

```


Subset table for export with selected columns.
```{r}

subP <- function(data) {
  cols <- grep("title|geo_accession|source_name|description|platform|characteristics|treatment", names(data))
  data <- data[, cols]
  data <- lapply(data, function(x) gsub("\n", " ", x))
  as.data.table(data)
} 

export <- lapply(results, subP)

```


Join data in one table and fill in additional columns.
```{r}

# Name for output file
reviewtable <- "sample_review.txt"

export <- rbindlist(export, fill = T)
export[, GSE := unlist(mapply(rep, gses, sapply(results, nrow)))]
newcols1 <- c("xpType", "RefDye", "Comment", "Group", "Batch", "Node", "NodeFunction", "BSM", "BSMDCD", "BSMDCD2", "BioSampName") 
export[, (newcols1) := ""]
export[, c("Ignore") := 0]
export[, c("XP") := 1]

export[, xpType := ixpType]
export[, isCTRL := iCTRL]
export[, BioSampName := iBiosamp]
export[, BSMDCD := iDCD]
export[, BSMDCD2 := iDCD2]

neworder <- c("GSE", newcols1[1:4], "Ignore", "XP", "isCTRL", newcols1[5:11], 
              "title", "geo_accession", grep("^source|treatment", names(export), val = T),
              grep("^char", names(export), val = T), "platform_id", grep("^desc", names(export), val = T))
setcolorder(export, neworder)

head(export)
write.table(export, reviewtable, sep = "\t", row.names = F, quote = F)

```

